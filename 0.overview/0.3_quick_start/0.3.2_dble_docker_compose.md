
## 0.3.2 dble 镜像本地build 
### 0.3.2.1 关于本节       
 + 本节内容为您介绍如何打包生成 dble 的 docker 镜像
 + 如何使用 docker-compose 快速搭建dble不同运行容器环境

### 0.3.2.2 准备
 + 安装docker
 + 安装docker-compose

### 0.3.2.3 打包过程

若使用dockerhub中的镜像，则可跳过下面的步骤。

1. 可以通过下面链接： http://blog.luckly-mjw.cn/tool-show/github-directory-downloader/index.html 下载dble项目下的 https://github.com/actiontech/dble/tree/master/docker-images 目录
2. 将下载的文件 dble_master_docker-images.zip 解压
```
mkdir -p $working_dir  
cd $working_dir  
unzip dble_master_docker-images.zip  
cd docker-images/dble-image
``` 
3. 执行命令生成 dble 镜像，其中 -t 指定 dble 镜像的 tag 名称，可以自己调整   
```
docker build --build-arg MODE=quick-start --build-arg DBLE_VERSION=latest -t="actiontech/dble:latest" .
``` 

有两个编译参数：  
**MODE**：指定 docker 镜像配置文件的模板样式，有三种，分别是：mgr，rwSplit，quick-start  
**DBLE_VERSION**：指定 docker 镜像所使用的 dble 的版本  

注意点：
1. 指定 MODE 后所使用的配置文件对应 $working_dir/docker-images/dble-image 下面各个文件夹里面的配置文件，如果需要自定义，请自行调整
2. 3.20.10.0版本的配置文件有重大变动，因此和 3.20.10.0 之前版本的配置文件是不兼容的，因此若使用 3.20.10.0 之前的版本做镜像，需要调整配置文件


### 0.3.2.4 docker-compose 运行镜像
在 dble 的源码目录结构中，$working_dir/docker-images 下分别有 mgr，quick-start，rwSplit 三个文件夹，每个文件夹中包含了各自运行的 docker-compose 文件，其中：  
 + mgr：启动两组mgr(六个mysql实例)，一个 dble  
 + quick-start：生成两个 mysql 实例，一个 dble  
 + rwSplit：生成一主一从两个 mysql 实例，一个 dble  

用户根据自己的需求选择一个文件夹，执行以下命令启动：
```
docker-compose up -d
```

在使用或者测试完毕之后，在使用以下指令回收对应资源
```
docker-compose stop
docker-compose rm
```

### 0.3.2.5 验证效果
#### 0.3.2.5.1 验证读写分离效果
1. 查看主从复制关系：

```
mysql> show slave status\G;
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 10.186.61.151
                  Master_User: user
                  Master_Port: 33306
                Connect_Retry: 60
              Master_Log_File: mysql-bin.000004
          Read_Master_Log_Pos: 154
               Relay_Log_File: 4bad16278f02-relay-bin.000006
                Relay_Log_Pos: 367
        Relay_Master_Log_File: mysql-bin.000004
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
              Replicate_Do_DB:
          Replicate_Ignore_DB:
           Replicate_Do_Table:
       Replicate_Ignore_Table:
      Replicate_Wild_Do_Table:
  Replicate_Wild_Ignore_Table:
                   Last_Errno: 0
                   Last_Error:
                 Skip_Counter: 0
          Exec_Master_Log_Pos: 154
              Relay_Log_Space: 747
              Until_Condition: None
               Until_Log_File:
                Until_Log_Pos: 0
           Master_SSL_Allowed: No
           Master_SSL_CA_File:
           Master_SSL_CA_Path:
              Master_SSL_Cert:
            Master_SSL_Cipher:
               Master_SSL_Key:
        Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No
                Last_IO_Errno: 0
                Last_IO_Error:
               Last_SQL_Errno: 0
               Last_SQL_Error:
  Replicate_Ignore_Server_Ids:
             Master_Server_Id: 1
                  Master_UUID: 46bb9692-e5f3-11ea-8340-0242ac110002
             Master_Info_File: /var/lib/mysql/master.info
                    SQL_Delay: 0
          SQL_Remaining_Delay: NULL
      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates
           Master_Retry_Count: 86400
                  Master_Bind:
      Last_IO_Error_Timestamp:
     Last_SQL_Error_Timestamp:
               Master_SSL_Crl:
           Master_SSL_Crlpath:
           Retrieved_Gtid_Set:
            Executed_Gtid_Set:
                Auto_Position: 0
         Replicate_Rewrite_DB:
                 Channel_Name:
           Master_TLS_Version:
1 row in set (0.00 sec)
```

#### 0.3.2.5.2 验证mgr效果
1. 查看两组mgr关系：

  ```
  [root@localhost]docker-images# docker exec mgr-a-1 mysql -h127.0.0.1 -p3306 -uroot -p123456 \
  -e "SHOW STATUS LIKE 'group_replication_primary_member';" \
  -e "SELECT * FROM performance_schema.replication_group_members;"

  +----------------------------------+--------------------------------------+
  | Variable_name                    | Value                                |
  +----------------------------------+--------------------------------------+
  | group_replication_primary_member | 72da84d7-0c4b-11eb-9f0e-0242ac120002 |
  +----------------------------------+--------------------------------------+
  +---------------------------+--------------------------------------+-------------+-------------+--------------+
  | CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |
  +---------------------------+--------------------------------------+-------------+-------------+--------------+
  | group_replication_applier | 72da84d7-0c4b-11eb-9f0e-0242ac120002 | mgr-a-1     |        3306 | ONLINE       |
  | group_replication_applier | 7314efdd-0c4b-11eb-ba28-0242ac120004 | mgr-a-3     |        3306 | ONLINE       |
  | group_replication_applier | 733b00fe-0c4b-11eb-bbea-0242ac120003 | mgr-a-2     |        3306 | ONLINE       |
  +---------------------------+--------------------------------------+-------------+-------------+--------------+

  [root@localhost]docker-images# docker exec mgr-b-1 mysql -h127.0.0.1 -p3306 -uroot -p123456 \
  -e "SHOW STATUS LIKE 'group_replication_primary_member';" \
  -e "SELECT * FROM performance_schema.replication_group_members;"

  +----------------------------------+--------------------------------------+
  | Variable_name                    | Value                                |
  +----------------------------------+--------------------------------------+
  | group_replication_primary_member | 728c327d-0c4b-11eb-9300-0242ac120005 |
  +----------------------------------+--------------------------------------+
  +---------------------------+--------------------------------------+-------------+-------------+--------------+
  | CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |
  +---------------------------+--------------------------------------+-------------+-------------+--------------+
  | group_replication_applier | 728c327d-0c4b-11eb-9300-0242ac120005 | mgr-b-1     |        3306 | ONLINE       |
  | group_replication_applier | 732c5b3b-0c4b-11eb-9eb1-0242ac120007 | mgr-b-3     |        3306 | ONLINE       |
  | group_replication_applier | 733c6350-0c4b-11eb-b0fb-0242ac120006 | mgr-b-2     |        3306 | ONLINE       |
  +---------------------------+--------------------------------------+-------------+-------------+--------------+
  ```
2. 观察dble日志, 进入dble-server容器查看/opt/dble/logs/下的相关日志

  ```
  [root@localhost]docker-images# docker exec -it dble-server bash
  [root@dble-server /]# less /opt/dble/logs/wrapper.log 
  [root@dble-server /]# less /opt/dble/logs/dble.log

  #bootstrap.cnf配置中useOuterHa参数配置为false时，才会有该日志生成
  [root@dble-server /]# less /opt/dble/logs/custom_mysql_ha.log 
  ```

3. 进入dble-server容器，查看/opt/dble/conf/db.xml配置如下：
  ```
  [root@localhost]# docker exec -it dble-server bash
  [root@dble-server /]# cat /opt/dble/conf/db.xml

  <dbGroup name="dbGroup1" rwSplitMode="2" delayThreshold="100">
      <heartbeat>show slave status</heartbeat>
      <dbInstance name="instanceM1" url="172.18.0.2:3306" user="root" password="123456" maxCon="300" minCon="10"
                  primary="true" readWeight="1" id="xx1">
      </dbInstance>
      <dbInstance name="instanceS1" url="172.18.0.3:3306" user="root" password="123456" maxCon="1000" minCon="10" readWeight="2">
          <property name="testOnCreate">false</property>
      </dbInstance>
      <dbInstance name="instanceS2" url="172.18.0.4:3306" user="root" password="123456" maxCon="1000" minCon="10" readWeight="2">
          <property name="testOnCreate">false</property>
      </dbInstance>
  </dbGroup>
  ```

4. 停用mgr-a-1的主实例，进入dble-server容器中查看变化：custom_mysql_ha.log中出现172.18.0.2:3066...is not alive、db.xml中dbGroup1组的主实例为instanceS1：

  ```
  [root@localhost]docker-images# docker-compose stop mgr-a-1
  [root@localhost]docker-images# docker exec -it dble-server bash
  [root@dble-server /]# less /opt/dble/logs/custom_mysql_ha.log
  ...
  2020-10-12 07:05:08 [DBLEDbGroupsCheck] [INFO] DbInstance 172.18.0.2:3306 in dbGroup1 is not alive!
  2020-10-12 07:05:08 [DBLEDbGroupsCheck] [INFO] DbInstance 172.18.0.3:3306 in dbGroup1 is normal!
  2020-10-12 07:05:08 [DBLEDbGroupsCheck] [INFO] DbInstance 172.18.0.4:3306 in dbGroup1 is normal!
  2020-10-12 07:05:08 [DBLEDbGroupsCheck] [INFO] DbInstance 172.18.0.5:3306 in dbGroup2 is normal!
  2020-10-12 07:05:08 [DBLEDbGroupsCheck] [INFO] DbInstance 172.18.0.6:3306 in dbGroup2 is normal!
  2020-10-12 07:05:08 [DBLEDbGroupsCheck] [INFO] DbInstance 172.18.0.7:3306 in dbGroup2 is normal!
  ...

  [root@dble-server /]# cat /opt/dble/conf/db.xml

  <dbGroup name="dbGroup1" rwSplitMode="2" delayThreshold="100">
      <heartbeat>show slave status</heartbeat>
      <dbInstance name="instanceM1" url="172.18.0.2:3306" user="root" password="123456" maxCon="300" minCon="10"
                   readWeight="1" id="xx1">
      </dbInstance>
      <dbInstance name="instanceS1" url="172.18.0.3:3306" user="root" password="123456" maxCon="1000" minCon="10" readWeight="2" primary="true">
          <property name="testOnCreate">false</property>
      </dbInstance>
      <dbInstance name="instanceS2" url="172.18.0.4:3306" user="root" password="123456" maxCon="1000" minCon="10" readWeight="2">
          <property name="testOnCreate">false</property>
      </dbInstance>
  </dbGroup>
  ```
